{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances \n",
    "from collections import defaultdict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amr_h\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (5,8,11,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe initialized\n",
      "--------------------------- (BEFORE) ---------------------------\n"
     ]
    }
   ],
   "source": [
    "## Train Data Reading & Preparation\n",
    "\n",
    "dtypes ={'ind_cco_fin_ult1': 'uint8', 'ind_deme_fin_ult1': 'uint8',\n",
    "            'ind_aval_fin_ult1': 'uint8', 'ind_valo_fin_ult1': 'uint8',\n",
    "            'ind_reca_fin_ult1': 'uint8', 'ind_ctju_fin_ult1': 'uint8',\n",
    "            'ind_cder_fin_ult1': 'uint8', 'ind_plan_fin_ult1': 'uint8',\n",
    "            'ind_fond_fin_ult1': 'uint8', 'ind_hip_fin_ult1': 'uint8',\n",
    "            'ind_pres_fin_ult1': 'uint8', 'ind_nomina_ult1': 'Int64', \n",
    "            'ind_cno_fin_ult1': 'uint8', 'ind_ctpp_fin_ult1': 'uint8',\n",
    "            'ind_ahor_fin_ult1': 'uint8', 'ind_dela_fin_ult1': 'uint8',\n",
    "            'ind_ecue_fin_ult1': 'uint8', 'ind_nom_pens_ult1': 'Int64',\n",
    "            'ind_recibo_ult1': 'uint8', 'ind_deco_fin_ult1': 'uint8',\n",
    "            'ind_tjcr_fin_ult1': 'uint8', 'ind_ctop_fin_ult1': 'uint8',\n",
    "            'ind_viv_fin_ult1': 'uint8', 'ind_ctma_fin_ult1': 'uint8',\n",
    "            'ncodpers' : 'uint32'} \n",
    "\n",
    "cols_to_cast={\"renta\":float}\n",
    "group_to_binary=['indfall','conyuemp','indext','indresi']\n",
    "kmeans_prediction=[]\n",
    "\n",
    "parse_dates = ['fecha_dato','fecha_alta']\n",
    "\n",
    "df= pd.read_csv(\"./datasets/train_ver2.csv\",dtype=dtypes, parse_dates=parse_dates)\n",
    "\n",
    "print('Dataframe initialized')\n",
    "df.shape\n",
    "\n",
    "print('--------------------------- (BEFORE) ---------------------------')\n",
    "# print('##################### DESCRIBE ')\n",
    "# print(df.describe())\n",
    "# print('##################### INFO ')\n",
    "# df.info()\n",
    "# print('##################### Null Count ')\n",
    "# np.sum(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- (AFTER) ---------------------------\n",
      "##################### Null Count \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58347484"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Cleaning\n",
    "\n",
    "# remove any duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "## seperate dates to day month year cols for model preditction\n",
    "df[\"fecha_dato\"] = pd.to_datetime(df[\"fecha_dato\"],format=\"%Y-%m-%d\")\n",
    "df[\"fecha_alta\"] = pd.to_datetime(df[\"fecha_alta\"],format=\"%Y-%m-%d\")\n",
    "df[\"ult_fec_cli_1t\"] = pd.to_datetime(df[\"ult_fec_cli_1t\"],format=\"%Y-%m-%d\")\n",
    "\n",
    "seperation_cols=['day','month','year']\n",
    "# for i in seperation_cols:\n",
    "df[\"fecha_dato_day\"] = pd.DatetimeIndex(df[\"fecha_dato\"]).day\n",
    "df[\"fecha_dato_month\"] = pd.DatetimeIndex(df[\"fecha_dato\"]).month\n",
    "df[\"fecha_dato_day\"] = pd.DatetimeIndex(df[\"fecha_dato\"]).year\n",
    "\n",
    "df[\"fecha_alta_day\"] = pd.DatetimeIndex(df[\"fecha_alta\"]).day\n",
    "df[\"fecha_alta_month\"] = pd.DatetimeIndex(df[\"fecha_alta\"]).month\n",
    "df[\"fecha_alta_year\"] = pd.DatetimeIndex(df[\"fecha_alta\"]).year\n",
    "\n",
    "df[\"ult_fec_cli_1t_day\"] = pd.DatetimeIndex(df[\"ult_fec_cli_1t\"]).day\n",
    "df[\"ult_fec_cli_1t_month\"] = pd.DatetimeIndex(df[\"ult_fec_cli_1t\"]).month\n",
    "df[\"ult_fec_cli_1t_year\"] = pd.DatetimeIndex(df[\"ult_fec_cli_1t\"]).year\n",
    "\n",
    "## convert age to numeric values and filling unknown values with the mean for each age group\n",
    "df[\"age\"]   = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[df.age < 18,\"age\"]  = df.loc[(df.age >= 18) & (df.age <= 30),\"age\"].mean(skipna=True)\n",
    "df.loc[df.age > 100,\"age\"] = df.loc[(df.age >= 30) & (df.age <= 100),\"age\"].mean(skipna=True)\n",
    "df[\"age\"].fillna(df[\"age\"].mean(),inplace=True)\n",
    "df[\"age\"]                  = df[\"age\"].astype(int)\n",
    "\n",
    "## fill missing cod_prov with 0\n",
    "df[\"cod_prov\"].fillna(0,inplace=True)\n",
    "\n",
    "# Drop some uneeded columns as tipodom is not useful and nomprov as province code already exists in cod_prov\n",
    "df.drop(['fecha_dato','fecha_alta','ult_fec_cli_1t','tipodom','nomprov'], axis=1, inplace=True)\n",
    "\n",
    "print('--------------------------- (AFTER) ---------------------------')\n",
    "# print('##################### INFO ')\n",
    "# df.info()\n",
    "print('##################### Null Count ')\n",
    "np.sum(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models and Helper Functions\n",
    "cosine_sim=None\n",
    "product_names = {\"ind_ahor_fin_ult1\" : \"Saving Account\",\"ind_aval_fin_ult1\" : \"Guarantees\",\"ind_cco_fin_ult1\" : \"Current Accounts\",\"ind_cder_fin_ult1\" : \"Derivada Account\",\n",
    "\"ind_cno_fin_ult1\" : \"Payroll Account\",\"ind_ctju_fin_ult1\" : \"Junior Account\",\"ind_ctma_fin_ult1\" : \"Más particular Account\",\"ind_ctop_fin_ult1\" : \"particular Account\",\n",
    "\"ind_ctpp_fin_ult1\" : \"particular Plus Account\",\"ind_deco_fin_ult1\" : \"Short-term deposits\",\"ind_deme_fin_ult1\" : \"Medium-term deposits\",\"ind_dela_fin_ult1\" : \"Long-term deposits\",\n",
    "\"ind_ecue_fin_ult1\" : \"e-account\",\"ind_fond_fin_ult1\" : \"Funds\",\"ind_hip_fin_ult1\" : \"Mortgage\",\"ind_plan_fin_ult1\" : \"Pensions\",\"ind_pres_fin_ult1\" : \"Loans\",\n",
    "\"ind_reca_fin_ult1\" : \"Taxes\",\"ind_tjcr_fin_ult1\" : \"Credit Card\",\"ind_valo_fin_ult1\" : \"Securities\",\"ind_viv_fin_ult1\" : \"Home Account\",\"ind_nomina_ult1\" : \"Payroll\",\n",
    "\"ind_nom_pens_ult1\" : \"Pensions\",\"ind_recibo_ult1\" : \"Direct Debit\"}\n",
    "\n",
    "province_names= {29: 'MALAGA', 13: 'CIUDAD REAL', 50: 'ZARAGOZA', 45: 'TOLEDO', 24: 'LEON', 20: 'GIPUZKOA', 10: 'CACERES', 17: 'GIRONA',\n",
    "                 49: 'ZAMORA', 8: 'BARCELONA', 37: 'SALAMANCA', 9: 'BURGOS', 22: 'HUESCA', 31: 'NAVARRA', 5: 'AVILA', 40: 'SEGOVIA',\n",
    "                 27: 'LUGO', 25: 'LERIDA', 28: 'MADRID', 3: 'ALICANTE', 42: 'SORIA', 41: 'SEVILLA', 39: 'CANTABRIA', 7: 'BALEARS, ILLES', \n",
    "                 47: 'VALLADOLID', 36: 'PONTEVEDRA', 46: 'VALENCIA', 44: 'TERUEL', 15: 'CORUÑA, A', 32: 'OURENSE', 23: 'JAEN',\n",
    "                 16: 'CUENCA', 48: 'BIZKAIA', 12: 'CASTELLON', 26: 'RIOJA, LA', 2: 'ALBACETE', 6: 'BADAJOZ', 30: 'MURCIA', 11: 'CADIZ',\n",
    "                 4: 'ALMERIA', 19: 'GUADALAJARA', 34: 'PALENCIA', 35: 'PALMAS, LAS', 14: 'CORDOBA', 21: 'HUELVA', 18: 'GRANADA', 33: 'ASTURIAS',\n",
    "                 38: 'SANTA CRUZ DE TENERIFE', 52: 'MELILLA', 43: 'TARRAGONA', 1: 'ALAVA', 51: 'CEUTA',0:'UNKNOWN'}\n",
    "\n",
    "def change_names(col_names, map_products):\n",
    "    '''\n",
    "    Change column names (e.g.\"ind_recibo_ult1\") to map names (e.g.\"Direct Debit\").\n",
    "    '''\n",
    "    return list(map(lambda col_name: map_products[col_name], col_names))\n",
    "\n",
    "\n",
    "def popularity_based(df):\n",
    "    \"\"\"\n",
    "    Function that calculates the probability of a product occurring. \n",
    "    Probability range is <0, 1>.\n",
    "    \"\"\"\n",
    "    top_col = {}\n",
    "    for col in df.columns[1:]:\n",
    "        top_col[col] = df[col].value_counts()[1]\n",
    "        \n",
    "#     sorted by most popular\n",
    "#     top_col = dict(sorted(top_col.items(), key=lambda it: it[1], reverse=True)) \n",
    "    \n",
    "    for k, v in top_col.items():\n",
    "        top_col[k] = np.around(v / df.shape[0], decimals=4)\n",
    "        \n",
    "    return top_col\n",
    "\n",
    "\n",
    "def useritem(user_id, df, sim_matrix = cosine_sim):\n",
    "    \"\"\"\n",
    "    Function that calculates recommendations for a given user.\n",
    "    It uses cosine similarity to calculate the most similar users.\n",
    "    Returns the probability of products for a given user based on similar users.\n",
    "    Probability range is <0, 1>.\n",
    "    \"\"\"\n",
    "    # computes the index in the user-item similarity matrix for a given user_id\n",
    "    cos_id = list(df.index).index(user_id) \n",
    "    \n",
    "    # number of similar users\n",
    "    k = 0\n",
    "    sim_min = 0.79\n",
    "    user_sim_k = {}\n",
    "    \n",
    "    while k < 20:\n",
    "        # creates the dictionary {'similar user':'similarity'}\n",
    "        for user in range(len(df)):\n",
    "            \n",
    "            # 0.99 because I don`t want the same user as user_id\n",
    "            if sim_min < sim_matrix[cos_id, user] < 0.99:\n",
    "                user_sim_k[user] = sim_matrix[cos_id, user]\n",
    "                k+=1\n",
    "                \n",
    "        sim_min -= 0.025\n",
    "        \n",
    "        # if there are no users with similarity at least 0.65, the recommendation probability will be set to 0 \n",
    "        if sim_min < 0.65:\n",
    "            break\n",
    "            \n",
    "    # sorted k most similar users\n",
    "    user_sim_k = dict(sorted(user_sim_k.items(), key=lambda item: item[1], reverse=True))\n",
    "    user_id_k = list(user_sim_k.keys()) \n",
    "    \n",
    "    # dataframe with k most similar users\n",
    "    df_user_k = df.iloc[user_id_k]\n",
    "    df_user_k_T = df_user_k.T\n",
    "    \n",
    "    # change the user index to the cosine index\n",
    "    df_user_k_T.columns = user_id_k\n",
    "    \n",
    "    # mean of ownership by k similar users\n",
    "    ownership = []\n",
    "    usit = {}\n",
    "    \n",
    "    for row_name, row in df_user_k_T.iterrows():\n",
    "        \n",
    "        for indx, own in row.items():\n",
    "            \n",
    "            ownership.append(own) \n",
    "        \n",
    "        usit[row_name] = np.mean(ownership)\n",
    "        ownership = []\n",
    "        \n",
    "    # if there are no users with similarity at least 0.65, the recommendation probability is 0 \n",
    "    if pd.isna(list(usit.values())[0]) == True:\n",
    "        \n",
    "        usit = {key : 0 for (key, value) in usit.items()}\n",
    "            \n",
    "    return usit\n",
    "\n",
    "def modelbased(user_id, df, model=DecisionTreeClassifier(max_depth=9)):\n",
    "    \"\"\"\n",
    "    Function that calculates recommendations for a given user.\n",
    "    It uses machine learning model to calculate the probability of products.\n",
    "    Probability range is <0, 1>.   \n",
    "    \"\"\"\n",
    "    \n",
    "    mdbs = {}\n",
    "    \n",
    "    for c in df.columns:\n",
    "        y_train = df[c].astype('int')\n",
    "        x_train = df.drop([c], axis = 1)\n",
    "        model.fit(x_train, y_train)\n",
    "        p_train = model.predict_proba(x_train[x_train.index == user_id])[:,1]\n",
    "        \n",
    "        mdbs[c] = p_train[0]\n",
    "        \n",
    "    return mdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLAYGROUND\n",
    " \n",
    "#df_light = df[:10000]\n",
    "# cosine_sim = 1 - pairwise_distances(df_light, metric=\"cosine\")\n",
    "\n",
    "#dum=pd.get_dummies(df_light)\n",
    "\n",
    "#dum.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "# dum.fillna(0.0, inplace=True)\n",
    "# df_light\n",
    "#df.ind_empleado.unique()\n",
    "# popularity_based(df)\n",
    "#modelbased(user_id=1061608,df=dum)\n",
    "\n",
    "# change_names([29.0],province_names)\n",
    "\n",
    "# change_names(['ind_ecue_fin_ult1'],product_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (NN-Handwriting-Recognizer)",
   "language": "python",
   "name": "pycharm-7e258e1b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
